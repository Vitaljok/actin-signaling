{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run params.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if 'name' in PARAMS:\n",
    "    None\n",
    "else:\n",
    "    from rules.enzymes import *\n",
    "    PARAMS['name'] = 'v01_oscillating_del_Arp2_3'\n",
    "    PARAMS['report_basins'] = [[Actin_BR, Actin_ST]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 53)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file_name = build_filename(PARAMS, \"simulations.h5\")\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for key in pd.HDFStore(data_file_name).keys():\n",
    "    df = df.append(pd.read_hdf(data_file_name, key=key))\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing cycles\n"
     ]
    }
   ],
   "source": [
    "def normalize_cycle(raw):\n",
    "    str1 = ''.join(str(e) for e in raw)    \n",
    "    return re.sub(r'^(.+?)\\1+$', r'\\1', str1)      \n",
    "\n",
    "def unique_cycles(ser):\n",
    "    cycles = ser.unique()\n",
    "    cycles_long = cycles * 10\n",
    "    cycles_map = {}\n",
    "\n",
    "    while len(cycles) > 0:\n",
    "        pattern = cycles[0]\n",
    "        target = normalize_cycle(pattern)\n",
    "        cycles = cycles[1:]\n",
    "        cycles_long = cycles_long[1:]\n",
    "\n",
    "        if pattern in cycles_map:        \n",
    "            continue\n",
    "\n",
    "        cycles_map[pattern] = target\n",
    "\n",
    "        for i in range(len(cycles)):\n",
    "            if len(re.findall('('+pattern+'){9}', cycles_long[i])) > 0:\n",
    "                cycles_map[cycles[i]] = target\n",
    "        \n",
    "    return cycles_map\n",
    "\n",
    "print(\"Normalizing cycles\")\n",
    "    \n",
    "for node in df.filter(regex=\"^cycle_.+(?<!norm)(?<!len)(?<!start)$\").columns.values:\n",
    "    cmap = unique_cycles(df[node])\n",
    "    df[\"%s_norm\" % node] = df[node].apply(lambda x: cmap[x])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporting simple basins\n"
     ]
    }
   ],
   "source": [
    "print(\"Reporting simple basins\")\n",
    "\n",
    "file = open(build_filename(PARAMS, \"simple_basins.txt\"), \"w\")\n",
    "\n",
    "for col in df.filter(regex=\"^cycle_.+_norm$\").columns:\n",
    "    grp = df.groupby(by=[col]).size().sort_values(ascending=False)\n",
    "    rep = pd.concat([grp.rename(\"count\"), (grp / df.shape[0]).rename('pct')], axis=1)\n",
    "    file.write(str(rep) + \"\\n\\n\\n\\n\")\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporting special basins\n"
     ]
    }
   ],
   "source": [
    "if 'report_basins' in PARAMS:\n",
    "    print(\"Reporting special basins\")\n",
    "    \n",
    "    file = open(build_filename(PARAMS, \"special_basins.txt\"), \"w\")\n",
    "\n",
    "    for cols in PARAMS['report_basins']:        \n",
    "        grp = df.groupby(by=[\"cycle_{}_norm\".format(name) for name in cols]).size().sort_values(ascending=False)\n",
    "        rep = pd.concat([grp.rename(\"count\"), (grp / df.shape[0]).rename('pct')], axis=1)\n",
    "        file.write(str(rep) + \"\\n\\n\\n\\n\")\n",
    "\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporting weighted activity\n"
     ]
    }
   ],
   "source": [
    "print(\"Reporting weighted activity\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "rep = pd.DataFrame(index = np.arange(0, 1, 0.1))\n",
    "\n",
    "for col in df.filter(regex=\"^cycle_.+_norm$\").columns:\n",
    "    grp = df.groupby(by=[col]).size().sort_values(ascending=False)\n",
    "    grp = pd.concat([grp.rename(\"count\"), (grp / df.shape[0]).rename('pct')], axis=1)\n",
    "    grp[\"active\"] = [len(x.replace('0', '')) / len(x) for x in grp.index.values]\n",
    "    grp[\"active_rel\"] = grp[\"pct\"] * grp[\"active\"] \n",
    "    \n",
    "    rep[col] = [grp[grp[\"pct\"] > cut][\"active_rel\"].sum() for cut in rep.index]\n",
    "    \n",
    "    \n",
    "rep.transpose().to_csv(build_filename(PARAMS, \"weighted_activity.csv\"), float_format='%g')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
